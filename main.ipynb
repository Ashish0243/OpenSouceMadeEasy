{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70edd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from pydantic import BaseModel,Field\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict,List\n",
    "import operator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import httpx\n",
    "from langchain_openai import ChatOpenAI,AzureChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d2426ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "load_dotenv()\n",
    "api_key=os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dcc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGoogleGenerativeAI(\n",
    "    api_key=api_key,\n",
    "    model='gemini-2.5-flash'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ed9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubRepoState(TypedDict):\n",
    "    username: str\n",
    "    repos: list[dict]\n",
    "    languages: list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6039d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GithubClient:\n",
    "    def __init__(self,token):\n",
    "        self.token = token\n",
    "        self.base_url=\"https://api.github.com/\"\n",
    "\n",
    "    def _headers(self):\n",
    "        return{\n",
    "            \"Authorization\": f\"Bearer {self.token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3+json\",\n",
    "        }\n",
    "    \n",
    "    def get_proj_repos(self,username):\n",
    "        response=httpx.get(f\"{self.base_url}users/{username}/repos\", headers=self._headers())\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def get_proj_languages(self,owner,repo):\n",
    "        response=httpx.get(f\"{self.base_url}repos/{owner}/{repo}/languages\", headers=self._headers())\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def get_proj_readme(self,owner,repo):\n",
    "        readme=httpx.get(f'https://raw.githubusercontent.com/{owner}/{repo[\"name\"]}/main/README.md')\n",
    "        if readme.status_code == 404:\n",
    "            return None  # README not found\n",
    "        readme.raise_for_status()  # raise for other unexpected errors\n",
    "\n",
    "        return readme.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cdb2cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_github_repos_details(state: GitHubRepoState):\n",
    "    client=GithubClient(token=os.getenv('GITHUB_TOKEN'))\n",
    "    repos=client.get_proj_repos(state[\"username\"])\n",
    "    languages=set()\n",
    "    required_repo_data=[]\n",
    "    for repo in repos:\n",
    "        readme=client.get_proj_readme(state[\"username\"],repo)\n",
    "        \n",
    "        required_data={\n",
    "            \"repository_name\": repo[\"name\"],\n",
    "            \"repository_url\":repo['html_url'],\n",
    "            \"repository_language_url\":repo['languages_url'],\n",
    "            \"repository_readme\": readme\n",
    "        }\n",
    "        languages_data=httpx.get(required_data['repository_language_url'], headers=client._headers())\n",
    "        languages_data.raise_for_status()\n",
    "        languages.update(languages_data.json().keys())\n",
    "        required_repo_data.append(required_data)\n",
    "\n",
    "    return {\"repos\": required_repo_data,\"languages\":list(languages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6db60ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadmeStructured(BaseModel):\n",
    "    frontend_frameworks: List[str] = Field(description=\"List the frontend frameworks,libraries and technology  mentioned in the README\")\n",
    "    backend_frameworks: List[str] = Field(description=\"List the backend frameworks,libraries and technology  mentioned in the README\")\n",
    "    database: List[str] = Field(description=\"List the databases mentioned in the README\")\n",
    "    tools: List[str] = Field(description=\"List the tools mentioned in the README\")\n",
    "\n",
    "readme_parser_model=model.with_structured_output(ReadmeStructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1f93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_readme(state: GitHubRepoState):\n",
    "    for repo in state[\"repos\"]:\n",
    "        readme_content = repo.get(\"repository_readme\", \"\")\n",
    "        prompt = f'''\n",
    "                You are given the README content of a GitHub repository.\n",
    "\n",
    "                Your task:\n",
    "                1. Carefully read the README text.\n",
    "                2. Extract information into the following JSON structure:\n",
    "\n",
    "                {{\n",
    "                \"frontend_frameworks\": [list of frontend frameworks,libraries and technology explicitly mentioned in the README],\n",
    "                \"backend_frameworks\": [list of backend frameworks,libraries and technologyexplicitly mentioned in the README],\n",
    "                \"database\": [list of databases explicitly mentioned in the README],\n",
    "                \"tools\": [list of tools explicitly mentioned in the README]\n",
    "                }}\n",
    "    \n",
    "                Rules:\n",
    "                - Only include a technology if it is **explicitly** mentioned in the README.\n",
    "                - If a category has no explicit mentions, set its value to `null` (NOT an empty string, NOT a guess).\n",
    "                - Do not infer or assume any technology from context ‚Äî if it‚Äôs not explicitly stated, return `null` for that category.\n",
    "                - Output must be **valid JSON** that strictly follows the given structure and field names.\n",
    "\n",
    "                README content:\n",
    "                {readme_content}\n",
    "        '''\n",
    "        refined_readme = readme_parser_model.invoke(prompt)\n",
    "        repo[\"repository_readme_structured\"] = refined_readme.model_dump()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fafbe9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000029682E439D0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=StateGraph(GitHubRepoState,\n",
    "                 merge={\n",
    "                     \"repos\": operator.add,\n",
    "                     \"languages\": operator.add\n",
    "                 })\n",
    "graph.add_node('get_github_repos_details',get_github_repos_details)\n",
    "graph.add_node('refine_readme',refine_readme)\n",
    "graph.add_edge(START,'get_github_repos_details')\n",
    "graph.add_edge('get_github_repos_details','refine_readme')\n",
    "graph.add_edge('refine_readme',END)\n",
    "workflow=graph.compile()\n",
    "\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93fb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': 'Ashish0243', 'repos': [{'repository_name': '1strep', 'repository_url': 'https://github.com/Ashish0243/1strep', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/1strep/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'Backend', 'repository_url': 'https://github.com/Ashish0243/Backend', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/Backend/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'Blog', 'repository_url': 'https://github.com/Ashish0243/Blog', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/Blog/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'Book-Store-Project', 'repository_url': 'https://github.com/Ashish0243/Book-Store-Project', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/Book-Store-Project/languages', 'repository_readme': '# Book-Store-Project\\nMaking an online book store project \\n', 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'care', 'repository_url': 'https://github.com/Ashish0243/care', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/care/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'ComConnect', 'repository_url': 'https://github.com/Ashish0243/ComConnect', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/ComConnect/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'Customer_Service', 'repository_url': 'https://github.com/Ashish0243/Customer_Service', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/Customer_Service/languages', 'repository_readme': '# üéØ ConnectDesk - Customer Service Platform\\n\\nA comprehensive customer service ticketing system built with Django, featuring real-time chat functionality and automated ticket assignment. üöÄ\\n\\n## ‚ú® Features\\n\\n- **üë• User Management**: Role-based system with customers and service providers\\n- **üé´ Ticket Management**: Create, track, and manage support tickets with UUID-based identification\\n- **üí¨ Real-time Chat**: WebSocket-based chat system for ticket communication\\n- **ü§ñ Automated Assignment**: Intelligent ticket assignment to least busy service providers\\n- **üîå RESTful API**: Complete API endpoints for all operations\\n- **üê≥ Containerized**: Docker-ready with MySQL and Redis support\\n\\n## üõ†Ô∏è Tech Stack\\n\\n- **üêç Backend**: Django 5.1.7, Django REST Framework\\n- **üóÑÔ∏è Database**: MySQL 8\\n- **‚ö° Cache/Message Broker**: Redis\\n- **üîå WebSockets**: Django Channels with Redis channel layer\\n- **üê≥ Containerization**: Docker & Docker Compose\\n- **üêç Python**: 3.13\\n\\n## üìÅ Project Structure\\n\\n```\\nConnectDesk/\\n‚îú‚îÄ‚îÄ Customer_Service/          # Main Django project\\n‚îÇ   ‚îú‚îÄ‚îÄ settings.py           # Django settings\\n‚îÇ   ‚îú‚îÄ‚îÄ urls.py              # URL configuration\\n‚îÇ   ‚îú‚îÄ‚îÄ asgi.py              # ASGI configuration for WebSockets\\n‚îÇ   ‚îî‚îÄ‚îÄ wsgi.py              # WSGI configuration\\n‚îú‚îÄ‚îÄ home/                     # Main application\\n‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Database models\\n‚îÇ   ‚îú‚îÄ‚îÄ views.py             # API views\\n‚îÇ   ‚îú‚îÄ‚îÄ serializers.py       # DRF serializers\\n‚îÇ   ‚îú‚îÄ‚îÄ consumers.py         # WebSocket consumers\\n‚îÇ   ‚îú‚îÄ‚îÄ signals.py           # Django signals\\n‚îÇ   ‚îî‚îÄ‚îÄ urls.py              # App URLs\\n‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies\\n‚îú‚îÄ‚îÄ Dockerfile               # Docker configuration\\n‚îú‚îÄ‚îÄ docker-compose.yml       # Multi-container setup\\n‚îî‚îÄ‚îÄ manage.py               # Django management script\\n```\\n\\n## üèóÔ∏è Models Overview\\n\\n### üë§ CustomUser\\n- Extends Django\\'s AbstractUser\\n- Role-based system: `CUSTOMER` or `SERVICE_PROVIDER`\\n- Automatic group assignment via signals\\n\\n### üé´ Tickets\\n- UUID-based primary key\\n- Status tracking: `OPEN`, `IN_PROGRESS`, `RESOLVED`, `CLOSED`\\n- Automatic assignment to least busy service provider\\n- Links customers with service providers\\n\\n### üí¨ ChatRoom & Messages\\n- One-to-one relationship with tickets\\n- Real-time messaging capability\\n- Automatic room code generation\\n\\n## üöÄ Installation & Setup\\n\\n### üìã Prerequisites\\n- üê≥ Docker & Docker Compose\\n- üêç Python 3.13 (for local development)\\n\\n### üê≥ Using Docker (Recommended)\\n\\n1. **üì• Clone the repository**\\n   ```bash\\n   git clone <repository-url>\\n   cd ConnectDesk\\n   ```\\n\\n2. **üî® Build and run with Docker Compose**\\n   ```bash\\n   docker-compose up --build\\n   ```\\n\\n3. **üîÑ Run migrations**\\n   ```bash\\n   docker-compose exec web python manage.py makemigrations\\n   docker-compose exec web python manage.py migrate\\n   ```\\n\\n4. **üë§ Create superuser**\\n   ```bash\\n   docker-compose exec web python manage.py createsuperuser\\n   ```\\n\\n5. **üåê Access the application**\\n   - API: http://localhost:8000/\\n   - Admin: http://localhost:8000/admin/\\n\\n### üíª Local Development Setup\\n\\n1. **üì¶ Install dependencies**\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n2. **‚öôÔ∏è Configure database**\\n   - Update `DATABASES` in `settings.py` for local MySQL setup\\n   - Or use SQLite for development\\n\\n3. **üîÑ Run migrations**\\n   ```bash\\n   python manage.py makemigrations\\n   python manage.py migrate\\n   ```\\n\\n4. **üèÉ Start development server**\\n   ```bash\\n   python manage.py runserver\\n   ```\\n\\n## üîå API Endpoints\\n\\n### üë• Users\\n- `GET /users/` - List all users\\n- `POST /users/` - Create new user\\n- `GET /users/{id}/` - Get user details\\n- `PUT /users/{id}/` - Update user\\n- `DELETE /users/{id}/` - Delete user\\n\\n### üé´ Tickets\\n- `GET /tickets/` - List all tickets\\n- `POST /tickets/` - Create new ticket\\n- `GET /tickets/{id}/` - Get ticket details\\n- `PUT /tickets/{id}/` - Update ticket\\n- `DELETE /tickets/{id}/` - Delete ticket\\n\\n### üí¨ WebSocket Chat\\n- `ws://localhost:8000/ws/chat/{room_code}` - Connect to chat room\\n\\n## üí° Usage Examples\\n\\n### üë§ Creating a User\\n```json\\nPOST /users/\\n{\\n    \"username\": \"john_doe\",\\n    \"password\": \"secure_password\",\\n    \"role\": \"CUSTOMER\"\\n}\\n```\\n\\n### üé´ Creating a Ticket\\n```json\\nPOST /tickets/\\n{\\n    \"customer_id\": 1,\\n    \"title\": \"Login Issue\",\\n    \"description\": \"Unable to log into my account\"\\n}\\n```\\n\\n### üí¨ WebSocket Chat Message\\n```json\\n{\\n    \"sender\": 1,\\n    \"message\": \"Hello, I need help with my account\"\\n}\\n```\\n\\n## üéØ Key Features Explained\\n\\n### ü§ñ Automatic Ticket Assignment\\n- New tickets are automatically assigned to the least busy service provider\\n- Uses Django ORM annotations to count active tickets per provider\\n\\n### üí¨ Real-time Chat\\n- WebSocket-based communication using Django Channels\\n- Messages are persisted in the database\\n- Room-based chat linked to specific tickets\\n\\n### üîê Role-based Access\\n- Automatic group assignment based on user role\\n- Signal-based group management\\n- Customizable permissions per role\\n\\n## ‚öôÔ∏è Configuration\\n\\n### üåç Environment Variables\\n- `DJANGO_SETTINGS_MODULE`: Django settings module\\n- `MYSQL_DATABASE`: Database name\\n- `MYSQL_USER`: Database user\\n- `MYSQL_PASSWORD`: Database password\\n\\n### üê≥ Docker Services\\n- **web**: Django application server\\n- **db**: MySQL 8 database\\n- **redis**: Redis for caching and channel layer\\n\\n## üë®\\u200düíª Development\\n\\n### üß™ Running Tests\\n```bash\\npython manage.py test\\n```\\n\\n### üîÑ Database Migrations\\n```bash\\npython manage.py makemigrations\\npython manage.py migrate\\n```\\n\\n### üêö Accessing Django Shell\\n```bash\\npython manage.py shell\\n```\\n\\n## Troubleshooting\\n\\n### Common Issues\\n\\n1. **Database Connection Error**\\n   - Ensure MySQL service is running\\n   - Check database credentials in settings\\n\\n2. **WebSocket Connection Failed**\\n   - Verify Redis is running\\n   - Check channel layer configuration\\n\\n3. **Permission Denied**\\n   - Ensure user groups are properly assigned\\n   - Check role-based permissions\\n\\n## Contributing\\n\\n1. Fork the repository\\n2. Create a feature branch\\n3. Make your changes\\n4. Run tests\\n5. Submit a pull request\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\n\\n## Support\\n\\nFor support and questions, please create an issue in the repository or contact the development team.\\n\\n---\\n\\n**Note**: This is a development setup. For production deployment, ensure you:\\n- Set `DEBUG = False`\\n- Configure proper secret keys\\n- Use environment variables for sensitive data\\n- Set up proper logging\\n- Configure static file serving\\n- Use a production-grade web server (e.g., Gunicorn with Nginx)\\n', 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': ['Django', 'Django REST Framework', 'Python', 'Django Channels', 'Gunicorn'], 'database': ['MySQL', 'Redis', 'SQLite'], 'tools': ['Docker', 'Docker Compose', 'Git', 'pip', 'Nginx']}}, {'repository_name': 'Data-Warehouse-Project', 'repository_url': 'https://github.com/Ashish0243/Data-Warehouse-Project', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/Data-Warehouse-Project/languages', 'repository_readme': \"\\n# Data Warehouse and Analytics Project\\n\\nWelcome to the **Data Warehouse and Analytics Project** repository! üöÄ  \\nThis project demonstrates a comprehensive data warehousing and analytics solution, from building a data warehouse to generating actionable insights. \\n\\n---\\n## üèóÔ∏è Data Architecture\\n\\nThe data architecture for this project follows Medallion Architecture **Bronze**, **Silver**, and **Gold** layers:\\n1. **Bronze Layer**: Stores raw data as-is from the source systems. Data is ingested from CSV Files into SQL Server Database.\\n2. **Silver Layer**: This layer includes data cleansing, standardization, and normalization processes to prepare data for analysis.\\n3. **Gold Layer**: Houses business-ready data modeled into a star schema required for reporting and analytics.\\n\\n---\\n## üìñ Project Overview\\n\\nThis project involves:\\n\\n1. **Data Architecture**: Designing a Modern Data Warehouse Using Medallion Architecture **Bronze**, **Silver**, and **Gold** layers.\\n2. **ETL Pipelines**: Extracting, transforming, and loading data from source systems into the warehouse.\\n3. **Data Modeling**: Developing fact and dimension tables optimized for analytical queries.\\n4. **Analytics & Reporting**: Creating SQL-based reports and dashboards for actionable insights.\\n\\n---\\n\\n## üõ†Ô∏è Important Links & Tools:\\n\\nEverything is for Free!\\n- **[Datasets](datasets/):** Access to the project dataset (csv files).\\n- **[SQL Server Express](https://www.microsoft.com/en-us/sql-server/sql-server-downloads):** Lightweight server for hosting your SQL database.\\n- **[SQL Server Management Studio (SSMS)](https://learn.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-ver16):** GUI for managing and interacting with databases.\\n- **[Git Repository](https://github.com/):** Set up a GitHub account and repository to manage, version, and collaborate on your code efficiently.\\n- **[DrawIO](https://www.drawio.com/):** Design data architecture, models, flows, and diagrams.\\n\\n---\\n\\n## üöÄ Project Requirements\\n\\n### Building the Data Warehouse (Data Engineering)\\n\\n#### Objective\\nDevelop a modern data warehouse using SQL Server to consolidate sales data, enabling analytical reporting and informed decision-making.\\n\\n#### Specifications\\n- **Data Sources**: Import data from two source systems (ERP and CRM) provided as CSV files.\\n- **Data Quality**: Cleanse and resolve data quality issues prior to analysis.\\n- **Integration**: Combine both sources into a single, user-friendly data model designed for analytical queries.\\n- **Scope**: Focus on the latest dataset only; historization of data is not required.\\n- **Documentation**: Provide clear documentation of the data model to support both business stakeholders and analytics teams.\\n\\n---\\n\\n## üìÇ Repository Structure\\n```\\ndata-warehouse-project/\\n‚îÇ\\n‚îú‚îÄ‚îÄ datasets/                           # Raw datasets used for the project (ERP and CRM data)\\n‚îÇ\\n‚îú‚îÄ‚îÄ docs/                               # Project documentation and architecture details\\n‚îÇ   ‚îú‚îÄ‚îÄ data_architecture.png           # File shows the project's architecture\\n‚îÇ   ‚îú‚îÄ‚îÄ data_catalog.md                 # Catalog of datasets, including field descriptions and metadata\\n‚îÇ   ‚îú‚îÄ‚îÄ data_flow.png                   # File for the data flow diagram\\n‚îÇ   ‚îú‚îÄ‚îÄ data_model.png                  # File for data models (star schema)\\n‚îÇ   ‚îú‚îÄ‚îÄ naming-conventions.md           # Consistent naming guidelines for tables, columns, and files\\n‚îÇ\\n‚îú‚îÄ‚îÄ scripts/                            # SQL scripts for ETL and transformations\\n‚îÇ   ‚îú‚îÄ‚îÄ bronze/                         # Scripts for extracting and loading raw data\\n‚îÇ   ‚îú‚îÄ‚îÄ silver/                         # Scripts for cleaning and transforming data\\n‚îÇ   ‚îú‚îÄ‚îÄ gold/                           # Scripts for creating analytical models\\n‚îÇ\\n‚îú‚îÄ‚îÄ tests/                              # Test scripts and quality files\\n‚îÇ\\n‚îú‚îÄ‚îÄ README.md                           # Project overview and instructions\\n‚îú‚îÄ‚îÄ LICENSE                             # License information for the repository\\n‚îú‚îÄ‚îÄ .gitignore                          # Files and directories to be ignored by Git\\n\\n```\\n---\\n\\n\\n\", 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': ['SQL Server'], 'tools': ['SQL Server Management Studio (SSMS)', 'Git', 'DrawIO']}}, {'repository_name': 'DJANGO-DOCKER-POSTGRESQL-SETUP', 'repository_url': 'https://github.com/Ashish0243/DJANGO-DOCKER-POSTGRESQL-SETUP', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/DJANGO-DOCKER-POSTGRESQL-SETUP/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'dj_celery', 'repository_url': 'https://github.com/Ashish0243/dj_celery', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/dj_celery/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'E-Commerce-DRF', 'repository_url': 'https://github.com/Ashish0243/E-Commerce-DRF', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/E-Commerce-DRF/languages', 'repository_readme': '# ShopFlow API - E-commerce REST API\\n\\nA comprehensive e-commerce REST API built with Django REST Framework that provides complete functionality for managing products, categories, shopping carts, orders, and user ratings.\\n\\n## üöÄ Features\\n\\n- **User Management**: Custom user model with email-based authentication\\n- **Product Management**: CRUD operations for products with categories\\n- **Shopping Cart**: Add, update, and manage cart items\\n- **Order Processing**: Complete order workflow with status tracking\\n- **Rating System**: Product rating and review functionality\\n- **Authentication**: JWT-based authentication with registration/login\\n- **Admin Interface**: Django admin for backend management\\n- **API Documentation**: Auto-generated OpenAPI/Swagger documentation\\n- **Async Tasks**: Celery integration for background tasks (email notifications)\\n- **Filtering & Search**: Advanced filtering and search capabilities\\n- **Pagination**: Built-in pagination for large datasets\\n\\n## üõ†Ô∏è Tech Stack\\n\\n- **Backend**: Django 5.2.1, Django REST Framework\\n- **Database**: SQLite (default), easily configurable for PostgreSQL/MySQL\\n- **Authentication**: JWT (Simple JWT), Django Allauth\\n- **Task Queue**: Celery with Redis\\n- **Documentation**: DRF Spectacular (OpenAPI/Swagger)\\n- **Image Handling**: Pillow for image uploads\\n- **Email**: SMTP email backend\\n- **Monitoring**: Django Silk for performance monitoring\\n\\n## üìã Prerequisites\\n\\n- Python 3.8+\\n- Redis (for Celery)\\n- Virtual environment (recommended)\\n\\n## üîß Installation\\n\\n1. **Clone the repository**\\n   ```bash\\n   git clone <repository-url>\\n   cd shopflow-api\\n   ```\\n\\n2. **Create and activate virtual environment**\\n   ```bash\\n   python -m venv venv\\n   source venv/bin/activate  # On Windows: venv\\\\Scripts\\\\activate\\n   ```\\n\\n3. **Install dependencies**\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n4. **Environment Configuration**\\n   Create a `.env` file in the root directory:\\n   ```env\\n   SECRET_KEY=your-secret-key-here\\n   DEBUG=True\\n   EMAIL_HOST_USER=your-email@gmail.com\\n   EMAIL_HOST_PASSWORD=your-email-password\\n   ```\\n\\n5. **Database Setup**\\n   ```bash\\n   python manage.py makemigrations\\n   python manage.py migrate\\n   ```\\n\\n6. **Create Superuser**\\n   ```bash\\n   python manage.py createsuperuser\\n   ```\\n\\n7. **Load Sample Data** (Optional)\\n   ```bash\\n   python manage.py popluate_db\\n   ```\\n\\n8. **Start Redis Server** (for Celery)\\n   ```bash\\n   redis-server\\n   ```\\n\\n9. **Start Celery Worker** (in separate terminal)\\n   ```bash\\n   celery -A E_COM worker --loglevel=info\\n   ```\\n\\n10. **Run Development Server**\\n    ```bash\\n    python manage.py runserver\\n    ```\\n\\n## üìö API Documentation\\n\\nOnce the server is running, access the API documentation at:\\n\\n- **Swagger UI**: `http://localhost:8000/api/schema/swagger-ui/`\\n- **ReDoc**: `http://localhost:8000/api/schema/redoc/`\\n- **OpenAPI Schema**: `http://localhost:8000/api/schema/`\\n\\n## üîê Authentication\\n\\nThe API uses JWT authentication. To access protected endpoints:\\n\\n1. **Register a new user**:\\n   ```\\n   POST /dj-rest-auth/registration/\\n   ```\\n\\n2. **Login**:\\n   ```\\n   POST /dj-rest-auth/login/\\n   ```\\n\\n3. **Get JWT Token**:\\n   ```\\n   POST /api/token/\\n   ```\\n\\n4. **Include token in requests**:\\n   ```\\n   Authorization: Bearer <your-jwt-token>\\n   ```\\n\\n## üì° API Endpoints\\n\\n### Authentication\\n- `POST /dj-rest-auth/registration/` - User registration\\n- `POST /dj-rest-auth/login/` - User login\\n- `POST /dj-rest-auth/logout/` - User logout\\n- `POST /api/token/` - Get JWT token\\n- `POST /api/token/refresh/` - Refresh JWT token\\n\\n### Products\\n- `GET /product/` - List all products (with filtering, search, pagination)\\n- `POST /product/` - Create new product (Admin only)\\n- `GET /product/{id}/` - Get product details\\n- `PUT /product/{id}/` - Update product (Admin only)\\n- `DELETE /product/{id}/` - Delete product (Admin only)\\n\\n### Categories\\n- `GET /category/` - List all categories (Admin only)\\n- `POST /category/` - Create new category (Admin only)\\n- `GET /category/{id}/` - Get category details (Admin only)\\n- `PUT /category/{id}/` - Update category (Admin only)\\n- `DELETE /category/{id}/` - Delete category (Admin only)\\n\\n### Cart\\n- `GET /cart/` - List all carts\\n- `POST /cart/` - Create new cart\\n- `GET /cart/{id}/` - Get cart details\\n- `PUT /cart/{id}/` - Update cart (add/remove items)\\n- `DELETE /cart/{id}/` - Delete cart\\n\\n### Orders\\n- `GET /order/` - List orders (filtered by user)\\n- `GET /order/{id}/` - Get order details\\n- `PUT /order/{id}/` - Update order status (Admin only)\\n- `DELETE /order/{id}/` - Cancel order (Admin only)\\n\\n### Ratings\\n- `GET /rating/` - List all ratings\\n- `POST /rating/` - Create new rating (Authenticated users)\\n- `GET /rating/{id}/` - Get rating details\\n- `PUT /rating/{id}/` - Update rating\\n- `DELETE /rating/{id}/` - Delete rating\\n\\n## üîç Filtering & Search\\n\\n### Products\\n- **Filter by price**: `?price=100` or `?price__gte=50&price__lte=200`\\n- **Filter by category**: `?category_slug=electronics`\\n- **Filter by stock**: `?stock__gt=0`\\n- **Search**: `?search=laptop`\\n- **Ordering**: `?ordering=price` or `?ordering=-price`\\n- **In-stock only**: Automatically filters in-stock products\\n\\n### Orders\\n- **Filter by status**: `?status=Confirmed`\\n- **Filter by date**: `?created_at__date=2024-01-01`\\n- **Filter by date range**: `?created_at__gte=2024-01-01&created_at__lte=2024-12-31`\\n\\n## üõí Shopping Cart Workflow\\n\\n1. **Create Cart**: User creates a new cart with products\\n2. **Add Items**: Add products to cart with quantities\\n3. **Update Cart**: Modify quantities or remove items\\n4. **Checkout**: Set `checked_out=true` to process the cart\\n5. **Order Creation**: System automatically creates order from cart\\n6. **Stock Update**: Product stock is automatically reduced\\n7. **Email Notification**: User receives order confirmation email\\n\\n## üìß Email Notifications\\n\\nThe system automatically sends email notifications for:\\n- Order confirmations\\n- Account registration (console backend in development)\\n\\nConfigure SMTP settings in `.env` for production email delivery.\\n\\n## üîí Permissions\\n\\n- **Public**: Product listing, product details\\n- **Authenticated**: Cart operations, order creation, ratings\\n- **Admin**: Product/category management, order management\\n\\n## üóÑÔ∏è Database Models\\n\\n### User\\n- Custom user model with email as username\\n- Fields: username, email, phone_number, first_name, last_name\\n\\n### Product\\n- Fields: name, description, price, stock, image, category\\n- Relationships: belongs to category, has many ratings\\n\\n### Category\\n- Fields: category_name, slug, description, image\\n- Auto-generates slug from category name\\n\\n### Cart\\n- Fields: user, date_added, checked_out\\n- Relationships: belongs to user, has many cart items\\n\\n### Order\\n- Fields: order_id (UUID), user, status, created_at\\n- Status choices: Pending, Confirmed, Cancelled\\n- Relationships: belongs to user, has many order items\\n\\n### Rating\\n- Fields: user, product, rating (1-5), review, created_at\\n- Relationships: belongs to user and product\\n\\n## üöÄ Production Deployment\\n\\n1. **Environment Variables**:\\n   ```env\\n   DEBUG=False\\n   SECRET_KEY=your-production-secret-key\\n   ALLOWED_HOSTS=your-domain.com\\n   DATABASE_URL=your-database-url\\n   REDIS_URL=your-redis-url\\n   ```\\n\\n2. **Database**: Configure PostgreSQL or MySQL\\n3. **Static Files**: Configure static file serving\\n4. **Media Files**: Configure media file storage (AWS S3, etc.)\\n5. **Celery**: Deploy with proper process management\\n6. **Security**: Enable HTTPS, configure security headers\\n\\n## üìä Performance Monitoring\\n\\nAccess Django Silk profiler at `/silk/` for:\\n- Request/response analysis\\n- Database query optimization\\n- Performance bottleneck identification\\n\\n\\n## ü§ù Contributing\\n\\n1. Fork the repository\\n2. Create a feature branch\\n3. Make your changes\\n4. Add tests for new functionality\\n5. Ensure all tests pass\\n6. Submit a pull request\\n\\n## üìù License\\n\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\n\\n## üÜò Support\\n\\nFor issues and questions:\\n- Create an issue in the GitHub repository\\n- Check the API documentation for endpoint details\\n- Review the Django and DRF documentation\\n\\n## üîÑ Changelog\\n\\n### v1.0.0\\n- Initial release with core e-commerce functionality\\n- JWT authentication\\n- Product and category management\\n- Shopping cart and order processing\\n- Rating system\\n- Email notifications\\n- API documentation\\n', 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': ['Django', 'Django REST Framework', 'JWT', 'Django Allauth', 'Pillow'], 'database': ['SQLite', 'PostgreSQL', 'MySQL'], 'tools': ['Swagger', 'Celery', 'Redis', 'DRF Spectacular', 'Django Silk', 'Python', 'Git']}}, {'repository_name': 'ExperimentingLangraph', 'repository_url': 'https://github.com/Ashish0243/ExperimentingLangraph', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/ExperimentingLangraph/languages', 'repository_readme': '# ExperimentingLangraph\\n', 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'Experimenting_Langchain', 'repository_url': 'https://github.com/Ashish0243/Experimenting_Langchain', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/Experimenting_Langchain/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'geo-location', 'repository_url': 'https://github.com/Ashish0243/geo-location', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/geo-location/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'gmail_fetcher', 'repository_url': 'https://github.com/Ashish0243/gmail_fetcher', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/gmail_fetcher/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'inventory-app', 'repository_url': 'https://github.com/Ashish0243/inventory-app', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/inventory-app/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'InventorySystem', 'repository_url': 'https://github.com/Ashish0243/InventorySystem', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/InventorySystem/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'OpenSouceMadeEasy', 'repository_url': 'https://github.com/Ashish0243/OpenSouceMadeEasy', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/OpenSouceMadeEasy/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'plio-backend', 'repository_url': 'https://github.com/Ashish0243/plio-backend', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/plio-backend/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}, {'repository_name': 'plio-quiz-backend', 'repository_url': 'https://github.com/Ashish0243/plio-quiz-backend', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/plio-quiz-backend/languages', 'repository_readme': '# Quiz Backend\\n\\n\\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\\n[![codecov](https://codecov.io/gh/avantifellows/quiz-backend/branch/main/graph/badge.svg)](https://codecov.io/gh/avantifellows/quiz-backend)\\n[![Discord](https://img.shields.io/discord/717975833226248303.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2&style=flat-square)](https://discord.gg/29qYD7fZtZ)\\n\\nThe backend for a generic mobile-friendly quiz engine created using FastAPI and MongoDB! The frontend can be found [here](https://github.com/avantifellows/quiz-frontend).\\n\\n## Table of Contents:\\n\\n  * [Installation](#installation)\\n    + [Local DB Setup](#local-db-setup)\\n      - [Linux Systems](#linux-systems)\\n      - [Mac Systems](#mac-systems)\\n    + [Virtual Environment Setup](#virtual-environment-setup)\\n  * [Running locally](#running-locally)\\n    + [How to pull the latest data from Prod / Staging DB to your local DB before you start working on a feature?](#how-to-pull-the-latest-data-from-prod---staging-db-to-your-local-db-before-you-start-working-on-a-feature-)\\n      - [What\\'s happening above?](#what-s-happening-above-)\\n  * [Deployment](#deployment)\\n  * [Tests](#tests)\\n\\n## Installation\\n\\n### Local DB Setup\\n\\n#### Linux Systems\\nThe following steps are for a Linux system.\\n- To run the backend locally, you would need to setup a local instance of mongodb. The offical instructions [here](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/) are good and simple enough to follow. Those steps are also listed down below.\\n\\n  - Import the public key used by the package management system.\\n  Issue the following command to import the MongoDB public GPG Key from [here](https://pgp.mongodb.com/server-6.0.asc):\\n    ```\\n    curl -fsSL https://pgp.mongodb.com/server-6.0.asc | \\\\\\n    sudo gpg -o /usr/share/keyrings/mongodb-server-6.0.gpg \\\\\\n    --dearmor\\n    ```\\n\\n  - From a terminal, install gnupg if it is not already available:\\n    ```\\n    sudo apt-get install gnupg\\n    ```\\n  - Create a list file for MongoDB.\\n    Create the list file `/etc/apt/sources.list.d/mongodb-org-6.0.list` for your version of Ubuntu. To check the Ubuntu version the host is running, open a terminal or shell on the host and execute\\n    ```\\n    lsb_release -dc\\n    ```\\n\\n    According to the version, run the respective code on the terminal. The below code is for the Ubuntu version 22.04(Jammy), if you have a different version running then replace the the below command according to your version from [here](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/#create-a-list-file-for-mongodb).\\n\\n      - Ubuntu 22.04 (Jammy)\\n        ```\\n        echo \"deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-6.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/6.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list\\n        ```\\n\\n  - Reload local package database.\\n    Issue the following command to reload the local package database:\\n    ```\\n    sudo apt-get update\\n    ```\\n  - Install the MongoDB packages\\n    Install the latest stable version of MongoDB\\n    ```\\n    sudo apt-get install -y mongodb-org\\n    ```\\n\\n\\n#### Mac Systems\\nThe following steps are for a Mac system.\\n- To run the backend locally, you would need to setup a local instance of mongodb. The offical instructions [here](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-os-x/#run-mongodb-community-edition) are good and simple enough to follow. Those steps are also listed down below.\\n\\n  - Install the Xcode command-line tools\\n    ```bash\\n    xcode-select --install\\n    ```\\n  - Make sure you have homebrew installed. If not, go [here](https://brew.sh/#install)\\n  - Download the official Homebrew formula for MongoDB\\n    ```bash\\n    brew tap mongodb/brew\\n    ```\\n  - Update Homebrew and all existing formulae\\n    ```bash\\n    brew update\\n    ```\\n  - Install MongoDB\\n    ```bash\\n    brew install mongodb-community@6.0\\n    ```\\n  - Make sure mongosh (your mongo shell) is added to the PATH. To test it out, type `mongosh` in your terminal and press enter. It should NOT give any error.\\n\\n### Virtual Environment Setup\\n\\n- Create a virtual environment (make sure that `virtualenv` is installed on your system):\\n  ```bash\\n  virtualenv venv\\n  ```\\n\\n- Activate the environment:\\n  ```bash\\n  source venv/bin/activate\\n  ```\\n\\n- Install the dependencies:\\n  ```bash\\n  pip install -r app/requirements.txt\\n  ```\\n\\n- Install `pre-commit`:\\n  ```\\n  pip install pre-commit\\n  ```\\n\\n- Set up `pre-commit`:\\n  ```\\n  pre-commit install\\n  ```\\n\\n- Copy `.env.example` to `.env` and set all the environment variables as mentioned in `docs/ENV.md`. No need to change anything if you\\'re planning to connect to a local DB. If you\\'re planning to connect your local server to a staging and prod DB, only then you need to change. PLEASE DO NOT CONNECT YOUR LOCAL INSTANCE TO STAGING/PROD DB.\\n\\n## Running locally\\nFor Linux machines, simply run the below in the terminal:\\n```bash\\nchmod +x startServerLinux.sh\\n./startServerLinux.sh\\n```\\nFor Mac Simply run:\\n\\n```bash\\nchmod +x startServerMac.sh\\n./startServerMac.sh\\n```\\n\\nYou should see a message like:\\n```bash\\nStarting the mongod process\\nService `mongodb-community` already started, use `brew services restart mongodb-community` to restart.\\nStarting the server now\\nINFO:     Will watch for changes in these directories: [\\'/Users/deepansh/Documents/Work/repos/quiz-backend/app\\']\\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\\nINFO:     Started reloader process [38899] using statreload\\nINFO:     Started server process [38901]\\nINFO:     Waiting for application startup.\\nINFO:     Application startup complete.\\n```\\n\\nUse `http://127.0.0.1:8000` as the base URL of the endpoints and navigate to `http://127.0.0.1:8000/docs` to see the auto-generated docs! :dancer:\\n\\n### How to pull the latest data from Prod / Staging DB to your local DB before you start working on a feature?\\n\\n\\nYou can pass arguments to the `startServerMac` script.\\n- `--freshSync` : Passing this argument means you\\'re telling the script to take a fresh sync from the cloud DB to your local DB. By default, this is false.\\n- `--source` : When `--freshSync` is specified, a source is also needed. Whether you need to sync from prod db or staging db. Please specify the full [mongo URI](https://www.mongodb.com/docs/manual/reference/connection-string/) of the DB you want to take a sync from. Note: Currently it might take 10-15 minutes for the sync process to be done. We\\'re working on improving this.\\n\\nExample:\\n```bash\\n./startServerMac.sh --freshSync --source mongodb+srv://quiz:<YOUR-PASSWORD>@quiz-staging-m10.uocfg.mongodb.net/quiz\\n```\\n\\nYou should see a message like:\\n```bash\\nStarting the mongod process\\nService `mongodb-community` already started, use `brew services restart mongodb-community` to restart.\\nFresh sync is true -- Going to remove current db and take a fresh sync\\n\\n\\nRemoving the existing data in the local database\\nCurrent Mongosh Log ID:\\t642317a1139325e074af0309\\nConnecting to:\\t\\tmongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+1.8.0\\nUsing MongoDB:\\t\\t6.0.5\\nUsing Mongosh:\\t\\t1.8.0\\n\\nFor mongosh info see: https://docs.mongodb.com/mongodb-shell/\\n\\n------\\n   The server generated these startup warnings when booting\\n   2023-03-27T15:17:54.237+05:30: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted\\n   2023-03-27T15:17:54.237+05:30: Soft rlimits for open file descriptors too low\\n------\\n\\n------\\n   Enable MongoDB\\'s free cloud-based monitoring service, which will then receive and display\\n   metrics about your deployment (disk utilization, CPU, operation statistics, etc).\\n\\n   The monitoring data will be available on a MongoDB website with a unique URL accessible to you\\n   and anyone you share the URL with. MongoDB may use this information to make product\\n   improvements and to suggest MongoDB products and deployment options to you.\\n\\n   To enable free monitoring, run the following command: db.enableFreeMonitoring()\\n   To permanently disable this reminder, run the following command: db.disableFreeMonitoring()\\n------\\n\\n{ ok: 1, dropped: \\'quiz\\' }\\nquiz DB dropped\\n\\n\\n\\nTaking a fresh sync from staging DB:\\n\\n\\nDownlading the data from staging DB\\n2023-03-28T22:06:51.043+0530\\tWARNING: On some systems, a password provided directly in a connection string or using --uri may be visible to system status programs such as `ps` that may be invoked by other users. Consider omitting the password to provide it via stdin, or using the --config option to specify a configuration file with the password.\\n2023-03-28T22:06:52.228+0530\\twriting quiz.quizzes to dump/quiz/quizzes.bson\\n2023-03-28T22:06:52.264+0530\\twriting quiz.session_answers to dump/quiz/session_answers.bson\\n2023-03-28T22:06:52.300+0530\\twriting quiz.sessions to dump/quiz/sessions.bson\\n2023-03-28T22:06:52.377+0530\\twriting quiz.questions to dump/quiz/questions.bson\\n2023-03-28T22:06:54.063+0530\\t[###.....................]          quiz.quizzes      101/611  (16.5%)\\n2023-03-28T22:06:54.064+0530\\t[........................]  quiz.session_answers  101/7868281   (0.0%)\\n2023-03-28T22:06:54.064+0530\\t[........................]         quiz.sessions   101/121840   (0.1%)\\n2023-03-28T22:06:54.064+0530\\t[........................]        quiz.questions    101/18467   (0.5%)\\n\\nData downloaded from staging DB, restoring the data in local DB\\n2023-03-28T22:40:05.949+0530\\tusing default \\'dump\\' directory\\n2023-03-28T22:40:05.951+0530\\tpreparing collections to restore from\\n2023-03-28T22:40:06.034+0530\\treading metadata for quiz.organization from dump/quiz/organization.metadata.json\\n2023-03-28T22:40:06.038+0530\\treading metadata for quiz.questions from dump/quiz/questions.metadata.json\\n2023-03-28T22:40:06.038+0530\\treading metadata for quiz.quizzes from dump/quiz/quizzes.metadata.json\\n2023-03-28T22:40:06.038+0530\\treading metadata for quiz.session_answers from dump/quiz/session_answers.metadata.json\\n2023-03-28T22:40:06.039+0530\\treading metadata for quiz.sessions from dump/quiz/sessions.metadata.json\\n\\nRemoving the downloaded dump folder\\nStarting the server now\\nINFO:     Will watch for changes in these directories: [\\'/Users/deepansh/Documents/Work/repos/quiz-backend/app\\']\\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\\nINFO:     Started reloader process [37464] using statreload\\nINFO:     Started server process [37466]\\nINFO:     Waiting for application startup.\\nINFO:     Application startup complete.\\n```\\n\\n\\n#### What\\'s happening above?\\n- mongo service is started using homebrew if not already started\\n- existing db is cleared\\n- a data dump from staging/prod db is taken\\n- the downloaded data is restored to the local db\\n- the downloaded dump is deleted\\n- virtual environment is started up and uvicorn app is started\\n\\n## Deployment\\n\\nWe are deploying our FastAPI instance on AWS Lambda which is triggered via an API Gateway. In order to automate the process, we are using [AWS SAM](https://www.youtube.com/watch?v=tA9IIGR6XFo&ab_channel=JavaHomeCloud), which creates the stack required for the deployment and updates it as needed with just a couple of commands and without having to do anything manually on the AWS GUI. Refer to [this](https://www.eliasbrange.dev/posts/deploy-fastapi-on-aws-part-1-lambda-api-gateway/) blog post for more details.\\n\\nThe actual deployment happens through Github Actions. Look at [`.github/workflows/deploy_to_staging.yml`](.github/workflows/deploy_to_staging.yml) for understanding the deployment to `Staging` and [`.github/workflows/deploy_to_prod.yml`](.github/workflows/deploy_to_prod.yml) for `Production`. Make sure to set all the environment variables mentioned in [`docs/ENV.md`](docs/ENV.md) in the `Production` and `Staging` environments in your Github repository.\\n\\n## Tests\\n- For testing, we use [`mongomock`](https://docs.mongoengine.org/guide/mongomock.html) package to mock our mongo database. To host this mock database, mongoDB process must run locally. Please install mongoDB following the instructions [here](https://www.mongodb.com/docs/manual/administration/install-community/). Ubuntu users may install using the command `pip install mongodb`.\\n- Create a folder `path/to/data/db` that mongoDB may use to store a local database. By default, `mongod` stores data in `/data/db`.\\n- Run the mongo daemon in a seperate terminal to start the host process in background.\\n```\\nmongod --dbpath path/to/data/db\\n```\\n- In case the above command does not work (lacks permissions, `data/db` not found), please check this [stackoverflow](https://stackoverflow.com/questions/22862808/mongod-command-not-found-os-x) thread.\\n- Finally, use the following command to run tests present in `app/tests`.\\n```\\npytest\\n```\\n\\n## Logs on Staging/Production\\n\\n- The quizzing engine is setup for generating detailed application logs. You can see the logging config in `app/logger_config.py` and it logs to the stdout and stderr. As the quizzing engine is setup to run on AWS Lambda, a separate log shipper is configured which ships logs from this lambda function to the Loki instance (which is what we\\'re using as our log aggregator).\\n- One can deploy the log shipper on AWS using the following steps:\\n  - Clone the official repo of loki onto your local. [Link Here](https://github.com/grafana/loki)\\n  - Navigate to `/tools/lambda-promtail`\\n  - Go through the `README.md` file in this folder. First step is to build the GO binary for the package and upload it to AWS ECR.\\n  - Running `docker build . -f tools/lambda-promtail/Dockerfile` from the root of the Loki repository will generate the image for you. Now upload it to ECR and note down the ECR URI of the image.\\n  - Now you can provision all the necessary resources by running a terraform script or a cloudformation script provided in the repo. We prefer cloudformation in this case.\\n  - Before running the cloudformation command, make sure to edit any required variables in your `template.yml` file. The only required thing in our case is updating the `MainLambdaPromtailSubscriptionFilter` resource. Update the `LogGroupName` for this resource. Point it to the log group name for your lambda function where your quiz engine backend is running.\\n  - Run this command on your local with the correct aws profile set:\\n    ```bash\\n    aws cloudformation create-stack \\\\\\n    --stack-name NAME_OF_YOUR_STACK \\\\\\n    --template-body file://template.yaml \\\\\\n    --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \\\\\\n    --region YOUR_REGION \\\\\\n    --parameters \\\\\\n        ParameterKey=WriteAddress,ParameterValue=YOUR_LOKI_HOST/loki/api/v1/push \\\\\\n        ParameterKey=LambdaPromtailImage,ParameterValue=YOUR_ECR_REPO:TAG \\\\\\n        ParameterKey=ExtraLabels,ParameterValue=\"env\\\\,staging\\\\,service\\\\,quizBackend\" \\\\\\n        ParameterKey=SkipTlsVerify,ParameterValue=\"true\"\\n\\n    ```\\n  - This will deploy your lambda promtail and your quizzing engine backend will be shipping logs to this promtail which in turn will be shipping logs to your loki instance. Now have fun exploring the logs on your Grafana dashboard!\\n', 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': ['FastAPI'], 'database': ['MongoDB'], 'tools': ['Homebrew', 'virtualenv', 'pre-commit', 'Uvicorn', 'AWS Lambda', 'API Gateway', 'AWS SAM', 'Github Actions', 'mongosh', 'pytest', 'mongomock', 'Loki', 'Grafana', 'CloudFormation', 'Terraform']}}, {'repository_name': 'SQL_DATA_ANALYSIS', 'repository_url': 'https://github.com/Ashish0243/SQL_DATA_ANALYSIS', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/SQL_DATA_ANALYSIS/languages', 'repository_readme': '# sql-data-analytics-project\\nA comprehensive collection of SQL scripts for data exploration, analytics, and reporting. These scripts cover various analyses such as database exploration, measures and metrics, time-based trends, cumulative analytics, segmentation, and more.\\n\\n', 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': ['SQL', 'Database'], 'tools': []}}, {'repository_name': 'yt_data_fetch', 'repository_url': 'https://github.com/Ashish0243/yt_data_fetch', 'repository_language_url': 'https://api.github.com/repos/Ashish0243/yt_data_fetch/languages', 'repository_readme': None, 'repository_readme_structured': {'frontend_frameworks': [], 'backend_frameworks': [], 'database': [], 'tools': []}}], 'languages': ['Shell', 'PowerShell', 'JavaScript', 'Python', 'Procfile', 'Makefile', 'SCSS', 'CSS', 'Typst', 'HTML', 'Jupyter Notebook', 'Dockerfile', 'TSQL']}\n"
     ]
    }
   ],
   "source": [
    "initial_state={\"username\":\"Ashish0243\"}\n",
    "final_state=workflow.invoke(initial_state)\n",
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
